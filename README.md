# -Dynamic-Parkour-AI-Coin-Collecting-Navigation-Agent

Dynamic Parkour AI Navigation Agent

Description:
An AI agent navigating a dynamic grid environment, collecting coins and avoiding obstacles while reaching a goal. Implements a strategic search algorithm balancing score optimization and safe movement in a challenging robotic parkour simulation.

A* search algorithm for intelligent navigation
Dynamic coin collection strategy
Obstacle avoidance
Score optimization

Algorithm: The goal of the overall algorithm I created was to collect as many coins as possible while avoiding collisions and obstacles to get the highest possible score. The main idea behind the algorithm I used to do this is to use the concept of an A* search which is an efficient search algorithm that will not stop until an optimal f value of the OPT(optimal path cost) is reached. The first key component to my whole algorithm is the absolDist function created. This function will be used throughout the algorithm for many different purposes: finding distances to the coins, finding the cost of different paths, and being a factor in calculating the total coin benefit. I created this function by passing in two location values. I applied a simple mathematical formula to calculate the distance as I summed the absolute value of the difference in x position and the difference in y position. The next component of the algorithm was to create the findCoinValues function which gives a reasonable estimate of what the potential value of a coin next to our agent would be based on the absolute distance(absolDist) between the current position of our agent and the location of the coin. This function iterates over a list of a bunch of coins and is implemented later on in the code when we need to calculate a heuristic for our A* search. I also created a coin benefit calculator function called calcCoinBenefit which provides us with a computed benefit value that tells us the benefit of moving towards coins within a specific proximity(in our case the radius was set to 2), influencing short-term decisions for our agent. This is necessary as without this function we would have a much harder time maximizing our score as we would not have a function that tells the agent which coins to go for. Another basic function I created was locGoalPos which loops through the whole map and outputs the coordinates of the goal, this function is useful just to know when the program can stop as when the agent reaches the goal we can terminate the game. Since our map is filled with obstacles and has walls preventing the agent from going beyond the set boundaries, it is important that every move our agent makes is legal and valid and does not go beyond the scope of the game. Due to this, there is a function I created which is called findValidMoves which ensures that any potential move does not go beyond the boundaries or hits an obstacle. Now that we have created all of our baseline helper functions, we get into the search component of the algorithm. An A* search algorithm needs a heuristic which can combine the costs and benefits of every possible state to help make an educated decision on which state to expand on. Thus, we create a heuristic function that can give us a heuristic value (based on our current position and the known goal position) to give to our A* algorithm. The heuristic we use is admissible which means that no matter what there will be a path that is less than or equal to the OPT. The other component of the A* algorithm is the greedy algorithm which minimizes the future cost which is what the function gAlgorithmCoinCollect simulates. Finally, the aStarGoal function is the function which finds the optimal path to the goal using the heuristic function and the greedy algorithm.  It integrates complex considerations like dynamic obstacles, coin positions, and other strategic factors. With these functions all set, the final logic_A  evaluates whether going after certain coins is strategically worth it compared to progressing towards the main goal. It coordinates between greedy coin collection and aStarGoal pathfinding function. It also considers time constraints and current game state to make decisions that optimize outcomes. 
